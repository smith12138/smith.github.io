<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Settings 组件分析</title>
      <link href="/2020/06/28/Settings%20%E7%BB%84%E4%BB%B6%E5%88%86%E6%9E%90/"/>
      <url>/2020/06/28/Settings%20%E7%BB%84%E4%BB%B6%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<ul><li><h4 id="COOKIES-ENABLED"><a href="#COOKIES-ENABLED" class="headerlink" title="COOKIES_ENABLED"></a>COOKIES_ENABLED</h4><p> 进入 scrapy 包 -&gt; downloadermiddlewares 子包 -&gt; cookies模块中</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CookiesMiddleware</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""This middleware enables working with sites that need cookies"""</span>    <span class="token comment" spellcheck="true"># 使用该中间件可以处理需要Cookie的网站</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>jars <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>CookieJar<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>debug <span class="token operator">=</span> debug    @classmethod    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 这是一个组件，作用于所有的scrapy Request</span>        <span class="token comment" spellcheck="true"># 通过这个组件，提取前一个Request中的cookie，并加入下一个Request cookie中去</span>        <span class="token keyword">if</span> <span class="token operator">not</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getbool<span class="token punctuation">(</span><span class="token string">'COOKIES_ENABLED'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> NotConfigured        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getbool<span class="token punctuation">(</span><span class="token string">'COOKIES_DEBUG'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> request<span class="token punctuation">.</span>meta<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'dont_merge_cookies'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span></code></pre></li></ul><hr><hr><ul><li><h4 id="USER-AGENT"><a href="#USER-AGENT" class="headerlink" title="USER_AGENT"></a>USER_AGENT</h4><p>设置全局USER_AGENT，与DOWNLOADERMIDDLEWARES 配合</p><pre><code>USER_AGENT = &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36&#39;</code></pre></li></ul><ul><li><h4 id="DOWNLOADER-MIDDLEWARES"><a href="#DOWNLOADER-MIDDLEWARES" class="headerlink" title="DOWNLOADER_MIDDLEWARES"></a>DOWNLOADER_MIDDLEWARES</h4><p> 赋予每个Scrapy Request USER-AGENT</p><pre><code>DOWNLOADER_MIDDLEWARES = {#    &#39;ArticleSpider.middlewares.ArticlespiderDownloaderMiddleware&#39;: 543,    &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;: 2}</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scrapy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计Lagou表结构</title>
      <link href="/2020/06/28/%E8%AE%BE%E8%AE%A1%E8%A1%A8%E7%BB%93%E6%9E%84/"/>
      <url>/2020/06/28/%E8%AE%BE%E8%AE%A1%E8%A1%A8%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h3 id="MySQL-表结构设计"><a href="#MySQL-表结构设计" class="headerlink" title="MySQL 表结构设计"></a>MySQL 表结构设计</h3><ul><li><p>分析网站数据，制定合理的表结构</p><p><img src="https://i.loli.net/2020/06/18/4IemkD7ZC6vVpzg.png" alt="如图所示"></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Practice </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CrawlSpider源码分析</title>
      <link href="/2020/06/28/CrawlSpider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2020/06/28/CrawlSpider%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="查看可用-scrapy-模板"><a href="#查看可用-scrapy-模板" class="headerlink" title="查看可用 scrapy 模板"></a>查看可用 scrapy 模板</h2><ul><li><h4 id="进入项目目录，输入以下命令"><a href="#进入项目目录，输入以下命令" class="headerlink" title="进入项目目录，输入以下命令"></a>进入项目目录，输入以下命令</h4><pre><code>scrapy genspider --list</code></pre><hr></li><li><h4 id="可用模板列表"><a href="#可用模板列表" class="headerlink" title="可用模板列表"></a>可用模板列表</h4><pre class=" language-python"><code class="language-python">Available templates<span class="token punctuation">:</span>  basic          <span class="token comment" spellcheck="true"># 默认模板</span>  crawl          <span class="token comment" spellcheck="true"># 全站爬取</span>  csvfeed      <span class="token comment" spellcheck="true"># CSV 源模板</span>  xmlfeed      <span class="token comment" spellcheck="true"># XML 源模板</span></code></pre><hr></li><li><h6 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h6></li></ul><ul><li><h6 id="crawl"><a href="#crawl" class="headerlink" title="crawl"></a>crawl</h6><p>CrawlSpider 是爬取那些具有一定规则网站的常用的爬虫，它基于Spider并有一些独特属性</p><ul><li><p>基于 Spider 类，进一步封装</p></li><li><p>rules: 是Rule 对象的集合，用于匹配目标网站并排除干扰</p></li><li><p>parse_start_url: 用于爬取起始响应，必须要返回item，Request中的一个</p></li><li><p>_parse_response: 是CrawlSpider 的核心方法</p></li></ul><blockquote><p><em>创建CrawlSpider</em></p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span> <span class="token operator">></span> scrapy genspider <span class="token operator">-</span>t crawl spider_name spider_url</code></pre></blockquote><p><strong>注意：在CrawlSpider中，不可以进行重构 parse 方法，因为它已经被CrawlSpider占用，可以使用parse_strat_url方法替代</strong></p></li><li><h6 id="csvfeed"><a href="#csvfeed" class="headerlink" title="csvfeed"></a>csvfeed</h6></li></ul><ul><li><h6 id="xmlfeed"><a href="#xmlfeed" class="headerlink" title="xmlfeed"></a>xmlfeed</h6></li></ul><hr><hr><ul><li><h4 id="添加-source-root-gt-settings-配置中"><a href="#添加-source-root-gt-settings-配置中" class="headerlink" title="添加 source root -&gt; settings 配置中"></a>添加 source root -&gt; settings 配置中</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 添加所属目录 -> PythonPath 中</span>sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></li></ul><ul><li><h4 id="CrawlSpider-源码逻辑概述"><a href="#CrawlSpider-源码逻辑概述" class="headerlink" title="CrawlSpider 源码逻辑概述"></a>CrawlSpider 源码逻辑概述</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LagouSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>    name <span class="token operator">=</span> <span class="token string">'lagou'</span>    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.lagou.com'</span><span class="token punctuation">]</span>    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.lagou.com/'</span><span class="token punctuation">]</span>    rules <span class="token operator">=</span> <span class="token punctuation">(</span>        <span class="token comment" spellcheck="true"># 参数为可迭代对象</span>        <span class="token comment" spellcheck="true"># rule 实例，LinkExtractor (链接提取器) 实例</span>        <span class="token comment" spellcheck="true"># 可以更改域名,  一般大型网站都有负载均衡处理, 在某个城市进行CDN, 每个城市的URL/IP地址都是不一样的, 获取到多个城市的URL后,可以进行随机IP访问，减少了IP被检测的概率</span>        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'Items/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">parse_job</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""解析拉勾网职位信息"""</span>        item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">#item['domain_id'] = response.xpath('//input[@id="sid"]/@value').get()</span>        <span class="token comment" spellcheck="true">#item['name'] = response.xpath('//div[@id="name"]').get()</span>        <span class="token comment" spellcheck="true">#item['description'] = response.xpath('//div[@id="description"]').get()</span>        <span class="token keyword">return</span> item<span class="token keyword">class</span> <span class="token class-name">CrawlSpider</span><span class="token punctuation">(</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>    rules <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 在 CrawlSpider 初始化时, 调用 compile_rules 方法</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>a<span class="token punctuation">,</span> <span class="token operator">**</span>kw<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>a<span class="token punctuation">,</span> <span class="token operator">**</span>kw<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_compile_rules<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_parse_response<span class="token punctuation">(</span>response<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse_start_url<span class="token punctuation">,</span> cb_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">parse_start_url</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">process_results</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> results<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> results    <span class="token keyword">def</span> <span class="token function">_build_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> rule_index<span class="token punctuation">,</span> link<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> Request<span class="token punctuation">(</span>            url<span class="token operator">=</span>link<span class="token punctuation">.</span>url<span class="token punctuation">,</span>            callback<span class="token operator">=</span>self<span class="token punctuation">.</span>_callback<span class="token punctuation">,</span>            errback<span class="token operator">=</span>self<span class="token punctuation">.</span>_errback<span class="token punctuation">,</span>            meta<span class="token operator">=</span>dict<span class="token punctuation">(</span>rule<span class="token operator">=</span>rule_index<span class="token punctuation">,</span> link_text<span class="token operator">=</span>link<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_requests_to_follow</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""要求遵循"""</span>        <span class="token comment" spellcheck="true"># 判断是否为 HTMLResponse</span>        <span class="token keyword">if</span> <span class="token operator">not</span> isinstance<span class="token punctuation">(</span>response<span class="token punctuation">,</span> HtmlResponse<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>        <span class="token comment" spellcheck="true"># 新建一个 set 类型局部变量, 对 response 中的 url 进行去重</span>        seen <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 通过 enumerate 把 _rules 改变为一个可迭代的对象</span>        <span class="token keyword">for</span> rule_index<span class="token punctuation">,</span> rule <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_rules<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 把 response 传递给 link_extractor 类 extract_links 方法, 提取出具体的 link</span>            links <span class="token operator">=</span> <span class="token punctuation">[</span>lnk <span class="token keyword">for</span> lnk <span class="token keyword">in</span> rule<span class="token punctuation">.</span>link_extractor<span class="token punctuation">.</span>extract_links<span class="token punctuation">(</span>response<span class="token punctuation">)</span>                     <span class="token keyword">if</span> lnk <span class="token operator">not</span> <span class="token keyword">in</span> seen<span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># 自定义 process_links 方法, 传递给 Rule 类, 抽取出 link 添加至 set 中</span>            <span class="token keyword">for</span> link <span class="token keyword">in</span> rule<span class="token punctuation">.</span>process_links<span class="token punctuation">(</span>links<span class="token punctuation">)</span><span class="token punctuation">:</span>                seen<span class="token punctuation">.</span>add<span class="token punctuation">(</span>link<span class="token punctuation">)</span>                request <span class="token operator">=</span> self<span class="token punctuation">.</span>_build_request<span class="token punctuation">(</span>rule_index<span class="token punctuation">,</span> link<span class="token punctuation">)</span>                <span class="token keyword">yield</span> rule<span class="token punctuation">.</span>_process_request<span class="token punctuation">(</span>request<span class="token punctuation">,</span> response<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_callback</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        rule <span class="token operator">=</span> self<span class="token punctuation">.</span>_rules<span class="token punctuation">[</span>response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'rule'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_parse_response<span class="token punctuation">(</span>response<span class="token punctuation">,</span> rule<span class="token punctuation">.</span>callback<span class="token punctuation">,</span> rule<span class="token punctuation">.</span>cb_kwargs<span class="token punctuation">,</span> rule<span class="token punctuation">.</span>follow<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_errback</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> failure<span class="token punctuation">)</span><span class="token punctuation">:</span>        rule <span class="token operator">=</span> self<span class="token punctuation">.</span>_rules<span class="token punctuation">[</span>failure<span class="token punctuation">.</span>request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'rule'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_handle_failure<span class="token punctuation">(</span>failure<span class="token punctuation">,</span> rule<span class="token punctuation">.</span>errback<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_parse_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> callback<span class="token punctuation">,</span> cb_kwargs<span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        CrawlSpider 中核心方法        :param response:        :param callback: 回调方法名 self.parse_start_url        :param cb_kwargs: 获取 parse_start_url 返回的参数        :param follow:        :return:        """</span>        <span class="token keyword">if</span> callback<span class="token punctuation">:</span>            cb_res <span class="token operator">=</span> callback<span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token operator">**</span>cb_kwargs<span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 交由 process_results 方法</span>            cb_res <span class="token operator">=</span> self<span class="token punctuation">.</span>process_results<span class="token punctuation">(</span>response<span class="token punctuation">,</span> cb_res<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 对返回结果，进行迭代(抛出 Item，交给 Scrapy 进行传递)</span>            <span class="token keyword">for</span> request_or_item <span class="token keyword">in</span> iterate_spider_output<span class="token punctuation">(</span>cb_res<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">yield</span> request_or_item        <span class="token comment" spellcheck="true"># CrawlSpider 核心中的核心, 默认进行跟随链接, 改变follow/_follow_links bool 值, 决定是否跟随</span>        <span class="token keyword">if</span> follow <span class="token operator">and</span> self<span class="token punctuation">.</span>_follow_links<span class="token punctuation">:</span>            <span class="token keyword">for</span> request_or_item <span class="token keyword">in</span> self<span class="token punctuation">.</span>_requests_to_follow<span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">yield</span> request_or_item    <span class="token keyword">def</span> <span class="token function">_handle_failure</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> failure<span class="token punctuation">,</span> errback<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> errback<span class="token punctuation">:</span>            results <span class="token operator">=</span> errback<span class="token punctuation">(</span>failure<span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> request_or_item <span class="token keyword">in</span> iterate_spider_output<span class="token punctuation">(</span>results<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">yield</span> request_or_item    <span class="token keyword">def</span> <span class="token function">_compile_rules</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""制定规则"""</span>        <span class="token comment" spellcheck="true"># 生成实例变量</span>        self<span class="token punctuation">.</span>_rules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> rule <span class="token keyword">in</span> self<span class="token punctuation">.</span>rules<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 浅拷贝 rule 值</span>            self<span class="token punctuation">.</span>_rules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>copy<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>rule<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>_rules<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>_compile<span class="token punctuation">(</span>self<span class="token punctuation">)</span>    @classmethod    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        spider <span class="token operator">=</span> super<span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>from_crawler<span class="token punctuation">(</span>crawler<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 获取 settings 中 'CRAWLSPIDER_FOLLOW_LINKS' 参数 (需自定义)，若没定义则取默认值 True</span>        <span class="token comment" spellcheck="true"># 若设置 'CRAWLSPIDER_FOLLOW_LINKS' 参数为False，rules 则会失效</span>        spider<span class="token punctuation">.</span>_follow_links <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getbool<span class="token punctuation">(</span><span class="token string">'CRAWLSPIDER_FOLLOW_LINKS'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> spider</code></pre><hr></li></ul><ul><li><h4 id="Rule-类"><a href="#Rule-类" class="headerlink" title="Rule 类"></a>Rule 类</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Rule</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> link_extractor<span class="token operator">=</span>None<span class="token punctuation">,</span> callback<span class="token operator">=</span>None<span class="token punctuation">,</span> cb_kwargs<span class="token operator">=</span>None<span class="token punctuation">,</span> follow<span class="token operator">=</span>None<span class="token punctuation">,</span>                 process_links<span class="token operator">=</span>None<span class="token punctuation">,</span> process_request<span class="token operator">=</span>None<span class="token punctuation">,</span> errback<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>link_extractor <span class="token operator">=</span> link_extractor <span class="token operator">or</span> _default_link_extractor        self<span class="token punctuation">.</span>callback <span class="token operator">=</span> callback        self<span class="token punctuation">.</span>errback <span class="token operator">=</span> errback        self<span class="token punctuation">.</span>cb_kwargs <span class="token operator">=</span> cb_kwargs <span class="token operator">or</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>process_links <span class="token operator">=</span> process_links <span class="token operator">or</span> _identity        self<span class="token punctuation">.</span>process_request <span class="token operator">=</span> process_request <span class="token operator">or</span> _identity_process_request        self<span class="token punctuation">.</span>process_request_argcount <span class="token operator">=</span> None        self<span class="token punctuation">.</span>follow <span class="token operator">=</span> follow <span class="token keyword">if</span> follow <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token keyword">else</span> <span class="token operator">not</span> callback</code></pre><ul><li>link_extractor                                       一个具体的 extractor 类，用于完成 url 的抽取</li><li>callback                                               回调函数</li><li>cb_kwargs                                           传递给 link_extractor 的参数</li><li>follow                                                   满足 rule 的 url 是否进行跟踪</li><li>process_links                                       可以自定义的预处理方法   <em>参数类型 -&gt; function</em></li><li>process_request                                  对 request 进行处理           <em>参数类型 -&gt; function</em></li></ul><hr></li></ul><ul><li><h4 id="LinkExtractor-类"><a href="#LinkExtractor-类" class="headerlink" title="LinkExtractor 类"></a>LinkExtractor 类</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LxmlLinkExtractor</span><span class="token punctuation">(</span>FilteringLinkExtractor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> allow<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> deny<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> allow_domains<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> deny_domains<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> restrict_xpaths<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                 tags<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'area'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> canonicalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                 unique<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> process_value<span class="token operator">=</span>None<span class="token punctuation">,</span> deny_extensions<span class="token operator">=</span>None<span class="token punctuation">,</span> restrict_css<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                 strip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> restrict_text<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        tags<span class="token punctuation">,</span> attrs <span class="token operator">=</span> set<span class="token punctuation">(</span>arg_to_iter<span class="token punctuation">(</span>tags<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> set<span class="token punctuation">(</span>arg_to_iter<span class="token punctuation">(</span>attrs<span class="token punctuation">)</span><span class="token punctuation">)</span>        lx <span class="token operator">=</span> LxmlParserLinkExtractor<span class="token punctuation">(</span>            tag<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x <span class="token keyword">in</span> tags<span class="token punctuation">,</span>            attr<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x <span class="token keyword">in</span> attrs<span class="token punctuation">,</span>            unique<span class="token operator">=</span>unique<span class="token punctuation">,</span>            process<span class="token operator">=</span>process_value<span class="token punctuation">,</span>            strip<span class="token operator">=</span>strip<span class="token punctuation">,</span>            canonicalized<span class="token operator">=</span>canonicalize        <span class="token punctuation">)</span>        super<span class="token punctuation">(</span>LxmlLinkExtractor<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>lx<span class="token punctuation">,</span> allow<span class="token operator">=</span>allow<span class="token punctuation">,</span> deny<span class="token operator">=</span>deny<span class="token punctuation">,</span>                                                allow_domains<span class="token operator">=</span>allow_domains<span class="token punctuation">,</span> deny_domains<span class="token operator">=</span>deny_domains<span class="token punctuation">,</span>                                                restrict_xpaths<span class="token operator">=</span>restrict_xpaths<span class="token punctuation">,</span> restrict_css<span class="token operator">=</span>restrict_css<span class="token punctuation">,</span>                                                canonicalize<span class="token operator">=</span>canonicalize<span class="token punctuation">,</span> deny_extensions<span class="token operator">=</span>deny_extensions<span class="token punctuation">,</span>                                                restrict_text<span class="token operator">=</span>restrict_text<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">extract_links</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Returns a list of :class:`~scrapy.link.Link` objects from the        specified :class:`response &lt;scrapy.http.Response>`.        Only links that match the settings passed to the ``__init__`` method of        the link extractor are returned.        Duplicate links are omitted.        """</span>        base_url <span class="token operator">=</span> get_base_url<span class="token punctuation">(</span>response<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>restrict_xpaths<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 编译 xpath 参数</span>            docs <span class="token operator">=</span> <span class="token punctuation">[</span>subdoc                    <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>restrict_xpaths                    <span class="token keyword">for</span> subdoc <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            docs <span class="token operator">=</span> <span class="token punctuation">[</span>response<span class="token punctuation">.</span>selector<span class="token punctuation">]</span>        all_links <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs<span class="token punctuation">:</span>            links <span class="token operator">=</span> self<span class="token punctuation">.</span>_extract_links<span class="token punctuation">(</span>doc<span class="token punctuation">,</span> response<span class="token punctuation">.</span>url<span class="token punctuation">,</span> response<span class="token punctuation">.</span>encoding<span class="token punctuation">,</span> base_url<span class="token punctuation">)</span>            all_links<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_process_links<span class="token punctuation">(</span>links<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> unique_list<span class="token punctuation">(</span>all_links<span class="token punctuation">)</span></code></pre><ul><li><p>allow                                                       正则提取，设定的 rules allow 参数，进行处理</p></li><li><p>deny                                                       正则提取，设定的 rules allow 参数，不处理</p></li><li><p>allow_domains                                       设定域名下的 url，进行处理</p></li><li><p>deny_domains                                        设定域名下的 url，不处理</p></li><li><p>restrict_xpaths                                        指定 xpath 规则，进行提取</p></li><li><p>tags                                                         默认提取标签 a, area  </p></li><li><p>attrs (attribute)                                        默认提取 href 属性中的值              </p></li><li><p>restrict_css                                             指定 css 规则，进行提取    <em>(最终都会被转换为 xpath 进行处理)</em></p><p>Ps：css 语法是 HTML 支持的， XML 是不支持的，最早 Xpath 是用来提取 XML 的</p></li></ul></li></ul><ul><li><h4 id="父类-FilteringLinkExtractor"><a href="#父类-FilteringLinkExtractor" class="headerlink" title="父类 FilteringLinkExtractor"></a>父类 FilteringLinkExtractor</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FilteringLinkExtractor</span><span class="token punctuation">:</span>    _csstranslator <span class="token operator">=</span> HTMLTranslator<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>lxmlhtml <span class="token keyword">import</span> LxmlLinkExtractor        <span class="token keyword">if</span> <span class="token punctuation">(</span>issubclass<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> FilteringLinkExtractor<span class="token punctuation">)</span> <span class="token operator">and</span>                <span class="token operator">not</span> issubclass<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> LxmlLinkExtractor<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            warn<span class="token punctuation">(</span><span class="token string">'scrapy.linkextractors.FilteringLinkExtractor is deprecated, '</span>                 <span class="token string">'please use scrapy.linkextractors.LinkExtractor instead'</span><span class="token punctuation">,</span>                 ScrapyDeprecationWarning<span class="token punctuation">,</span> stacklevel<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> super<span class="token punctuation">(</span>FilteringLinkExtractor<span class="token punctuation">,</span> cls<span class="token punctuation">)</span><span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> link_extractor<span class="token punctuation">,</span> allow<span class="token punctuation">,</span> deny<span class="token punctuation">,</span> allow_domains<span class="token punctuation">,</span> deny_domains<span class="token punctuation">,</span>                 restrict_xpaths<span class="token punctuation">,</span> canonicalize<span class="token punctuation">,</span> deny_extensions<span class="token punctuation">,</span> restrict_css<span class="token punctuation">,</span> restrict_text<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>link_extractor <span class="token operator">=</span> link_extractor        self<span class="token punctuation">.</span>allow_res <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> _re_type<span class="token punctuation">)</span> <span class="token keyword">else</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                          <span class="token keyword">for</span> x <span class="token keyword">in</span> arg_to_iter<span class="token punctuation">(</span>allow<span class="token punctuation">)</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>deny_res <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> _re_type<span class="token punctuation">)</span> <span class="token keyword">else</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                         <span class="token keyword">for</span> x <span class="token keyword">in</span> arg_to_iter<span class="token punctuation">(</span>deny<span class="token punctuation">)</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>allow_domains <span class="token operator">=</span> set<span class="token punctuation">(</span>arg_to_iter<span class="token punctuation">(</span>allow_domains<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>deny_domains <span class="token operator">=</span> set<span class="token punctuation">(</span>arg_to_iter<span class="token punctuation">(</span>deny_domains<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>restrict_xpaths <span class="token operator">=</span> tuple<span class="token punctuation">(</span>arg_to_iter<span class="token punctuation">(</span>restrict_xpaths<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>restrict_xpaths <span class="token operator">+=</span> tuple<span class="token punctuation">(</span>map<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_csstranslator<span class="token punctuation">.</span>css_to_xpath<span class="token punctuation">,</span>                                          arg_to_iter<span class="token punctuation">(</span>restrict_css<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>canonicalize <span class="token operator">=</span> canonicalize        <span class="token keyword">if</span> deny_extensions <span class="token keyword">is</span> None<span class="token punctuation">:</span>            deny_extensions <span class="token operator">=</span> IGNORED_EXTENSIONS        self<span class="token punctuation">.</span>deny_extensions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'.'</span> <span class="token operator">+</span> e <span class="token keyword">for</span> e <span class="token keyword">in</span> arg_to_iter<span class="token punctuation">(</span>deny_extensions<span class="token punctuation">)</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>restrict_text <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> _re_type<span class="token punctuation">)</span> <span class="token keyword">else</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                              <span class="token keyword">for</span> x <span class="token keyword">in</span> arg_to_iter<span class="token punctuation">(</span>restrict_text<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">_link_allowed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> link<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">not</span> _is_valid_url<span class="token punctuation">(</span>link<span class="token punctuation">.</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>allow_res <span class="token operator">and</span> <span class="token operator">not</span> _matches<span class="token punctuation">(</span>link<span class="token punctuation">.</span>url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>allow_res<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>deny_res <span class="token operator">and</span> _matches<span class="token punctuation">(</span>link<span class="token punctuation">.</span>url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>deny_res<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        parsed_url <span class="token operator">=</span> urlparse<span class="token punctuation">(</span>link<span class="token punctuation">.</span>url<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>allow_domains <span class="token operator">and</span> <span class="token operator">not</span> url_is_from_any_domain<span class="token punctuation">(</span>parsed_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>allow_domains<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>deny_domains <span class="token operator">and</span> url_is_from_any_domain<span class="token punctuation">(</span>parsed_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>deny_domains<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>deny_extensions <span class="token operator">and</span> url_has_any_extension<span class="token punctuation">(</span>parsed_url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>deny_extensions<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>restrict_text <span class="token operator">and</span> <span class="token operator">not</span> _matches<span class="token punctuation">(</span>link<span class="token punctuation">.</span>text<span class="token punctuation">,</span> self<span class="token punctuation">.</span>restrict_text<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">return</span> <span class="token boolean">True</span>    <span class="token keyword">def</span> <span class="token function">matches</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>allow_domains <span class="token operator">and</span> <span class="token operator">not</span> url_is_from_any_domain<span class="token punctuation">(</span>url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>allow_domains<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>deny_domains <span class="token operator">and</span> url_is_from_any_domain<span class="token punctuation">(</span>url<span class="token punctuation">,</span> self<span class="token punctuation">.</span>deny_domains<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        allowed <span class="token operator">=</span> <span class="token punctuation">(</span>regex<span class="token punctuation">.</span>search<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">for</span> regex <span class="token keyword">in</span> self<span class="token punctuation">.</span>allow_res<span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>allow_res <span class="token keyword">else</span> <span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">]</span>        denied <span class="token operator">=</span> <span class="token punctuation">(</span>regex<span class="token punctuation">.</span>search<span class="token punctuation">(</span>url<span class="token punctuation">)</span> <span class="token keyword">for</span> regex <span class="token keyword">in</span> self<span class="token punctuation">.</span>deny_res<span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>deny_res <span class="token keyword">else</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> any<span class="token punctuation">(</span>allowed<span class="token punctuation">)</span> <span class="token operator">and</span> <span class="token operator">not</span> any<span class="token punctuation">(</span>denied<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_process_links</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> links<span class="token punctuation">)</span><span class="token punctuation">:</span>        links <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> links <span class="token keyword">if</span> self<span class="token punctuation">.</span>_link_allowed<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>canonicalize<span class="token punctuation">:</span>            <span class="token keyword">for</span> link <span class="token keyword">in</span> links<span class="token punctuation">:</span>                link<span class="token punctuation">.</span>url <span class="token operator">=</span> canonicalize_url<span class="token punctuation">(</span>link<span class="token punctuation">.</span>url<span class="token punctuation">)</span>        links <span class="token operator">=</span> self<span class="token punctuation">.</span>link_extractor<span class="token punctuation">.</span>_process_links<span class="token punctuation">(</span>links<span class="token punctuation">)</span>        <span class="token keyword">return</span> links    <span class="token keyword">def</span> <span class="token function">_extract_links</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>link_extractor<span class="token punctuation">.</span>_extract_links<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Top-level imports</span><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors<span class="token punctuation">.</span>lxmlhtml <span class="token keyword">import</span> LxmlLinkExtractor <span class="token keyword">as</span> LinkExtractor  </code></pre></li></ul><ul><li><h4 id="引用-HTMLTranslator-类"><a href="#引用-HTMLTranslator-类" class="headerlink" title="引用 HTMLTranslator 类"></a>引用 HTMLTranslator 类</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">HTMLTranslator</span><span class="token punctuation">(</span>TranslatorMixin<span class="token punctuation">,</span> OriginalHTMLTranslator<span class="token punctuation">)</span><span class="token punctuation">:</span>    @lru_cache<span class="token punctuation">(</span>maxsize<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">css_to_xpath</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> css<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">'descendant-or-self::'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> super<span class="token punctuation">(</span>HTMLTranslator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>css_to_xpath<span class="token punctuation">(</span>css<span class="token punctuation">,</span> prefix<span class="token punctuation">)</span></code></pre><ul><li>css 转换 xpath</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scrapy </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
